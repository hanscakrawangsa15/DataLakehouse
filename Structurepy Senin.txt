# Struktur ETL Data Warehouse (Sensor + Tweet + Competitor)
import pandas as pd
from sqlalchemy import create_engine
from datetime import datetime
from sqlalchemy import text
import tkinter as tk
from matplotlib.figure import Figure
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

# Koneksi database - sebaiknya dipindahkan ke file konfigurasi terpisah
STAGGING_DB = 'postgresql://postgres:chriscakra15@localhost:5432/staging'
DWH_DB = 'postgresql://postgres:chriscakra15@localhost:5432/AdventureworksDW'
engine_stag = create_engine(STAGGING_DB)
engine_dwh = create_engine(DWH_DB)

def check_table_exists_and_has_data(engine, table_name, schema='dwh'):
    """Memeriksa apakah tabel ada dan memiliki data"""
    try:
        df = pd.read_sql(f"SELECT * FROM {schema}.{table_name} LIMIT 1", con=engine)
        if df.empty:
            print(f"WARNING: Tabel {table_name} kosong!")
            return False
        return True
    except:
        print(f"WARNING: Tabel {table_name} tidak ditemukan!")
        return False

def check_staging_data():
    """Memeriksa ketersediaan data di staging database"""
    print("\nMemeriksa data di staging database...")
    tables = ['staging_warehouse_temp_sensor', 'staging_market_share_report', 'staging_external_sentiment']
    for table in tables:
        try:
            df = pd.read_sql(f"SELECT * FROM {table} LIMIT 1", con=engine_stag)
            if df.empty:
                print(f"WARNING: Tabel staging {table} kosong!")
            else:
                print(f"Data tersedia: Tabel staging {table} memiliki data")
        except:
            print(f"WARNING: Tabel staging {table} tidak ditemukan!")

def check_warehouse_data():
    """Memeriksa ketersediaan data di data warehouse"""
    print("\nMemeriksa data di warehouse...")
    tables = ['dim_sensor', 'dim_time', 'dim_tweet', 'dim_competitor', 'fact_temperature', 'fact_sentiment', 'fact_competitor_share']
    for table in tables:
        check_table_exists_and_has_data(engine_dwh, table)

def load_dim_competitor():
    """Memuat data competitor ke dalam dimensi"""
    try:
        print("\nMemuat data ke dim_competitor...")
        df = pd.read_sql("SELECT DISTINCT company FROM staging_market_share_report", con=engine_stag)
        df_new = df[~df['company'].isin(
            pd.read_sql("SELECT company FROM dwh.dim_competitor", con=engine_dwh)['company']
        )]

        if df_new.empty:
            print("Tidak ada competitor baru.")
            return

        df_new.to_sql('dim_competitor', con=engine_dwh, schema='dwh', if_exists='append', index=False)
        print(f"{len(df_new)} competitor berhasil dimasukkan.")
    except Exception as e:
        print(f"Gagal memuat dim_competitor: {e}")

def load_fact_competitor_share():
    """Memuat data market share competitor"""
    try:
        print("\nMemuat data ke fact_competitor_share...")
        query = """
        SELECT s.company, s.market_share_percent, dt.time_id
        FROM staging_market_share_report s
        JOIN dwh.dim_competitor dc ON dc.company = s.company
        JOIN dwh.dim_time dt ON dt.date = CURRENT_DATE
        """

        df = pd.read_sql(query, con=engine_stag)
        if df.empty:
            print("Tidak ada data untuk dimasukkan ke fact_competitor_share.")
            return

        comp_map = pd.read_sql("SELECT competitor_id, company FROM dwh.dim_competitor", con=engine_dwh)
        df = df.merge(comp_map, on='company')

        df[['competitor_id', 'market_share_percent', 'time_id']].to_sql(
            'fact_competitor_share',
            con=engine_dwh,
            schema='dwh',
            if_exists='append',
            index=False
        )
        print(f"{len(df)} data berhasil dimasukkan ke fact_competitor_share.")
    except Exception as e:
        print(f"Error memuat fact_competitor_share: {e}")

def load_dim_tweet():
    """Memuat data tweet ke dalam dimensi"""
    print("\nMemuat data ke dim_tweet...")
    df = pd.read_sql("SELECT DISTINCT tweet_id, tweet_text FROM staging_external_sentiment", con=engine_stag)
    df['author_id'] = 'unknown'
    df = df[['tweet_id', 'author_id', 'tweet_text']]

    existing = pd.read_sql("SELECT tweet_id FROM dwh.dim_tweet", con=engine_dwh)
    df = df[~df['tweet_id'].isin(existing['tweet_id'])]

    if df.empty:
        print("Tidak ada tweet baru.")
        return

    df.to_sql('dim_tweet', con=engine_dwh, schema='dwh', if_exists='append', index=False)
    print(f"{len(df)} tweet berhasil dimasukkan.")

def load_dim_topic():
    """Memuat data topik tweet"""
    print("\nMemuat data ke dim_topic...")
    df = pd.read_sql("SELECT DISTINCT matched_product FROM staging_external_sentiment", con=engine_stag)
    df['keyword'] = df['matched_product']
    df = df[['keyword']].dropna().drop_duplicates()
    
    existing = pd.read_sql("SELECT keyword FROM dwh.dim_topic", con=engine_dwh)
    df = df[~df['keyword'].isin(existing['keyword'])]

    if df.empty:
        print("Tidak ada topik baru.")
        return

    df.to_sql('dim_topic', con=engine_dwh, schema='dwh', if_exists='append', index=False)
    print(f"{len(df)} topik dimasukkan.")

def load_fact_sentiment():
    """Memuat data sentimen ke dalam fact table"""
    try:
        print("\nMemuat data ke fact_sentiment...")
        
        # Create fact_sentiment table if it doesn't exist
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS dwh.fact_sentiment (
            fact_id SERIAL PRIMARY KEY,
            tweet_id VARCHAR(50) NOT NULL,
            topic_id INT,
            time_id INT,
            polarity INT,
            FOREIGN KEY (tweet_id) REFERENCES dwh.dim_tweet(tweet_id),
            FOREIGN KEY (topic_id) REFERENCES dwh.dim_topic(topic_id),
            FOREIGN KEY (time_id) REFERENCES dwh.dim_time(time_id)
        )
        """
        with engine_dwh.connect() as connection:
            connection.execute(text(create_table_sql))
            connection.commit()
        
        # Get sentiment data from staging
        df = pd.read_sql("""
            SELECT tweet_id, sentiment, timestamp, matched_product 
            FROM staging_external_sentiment
        """, con=engine_stag)
        
        if df.empty:
            print("Tidak ada data sentimen baru yang ditemukan di staging.")
            return
            
        # Map sentiment to polarity
        df['polarity'] = df['sentiment'].map({'positive': 1, 'negative': -1, 'neutral': 0}).fillna(0)
        
        # Get dimension mappings
        tweet_map = pd.read_sql("SELECT tweet_id FROM dwh.dim_tweet", con=engine_dwh)
        topic_map = pd.read_sql("SELECT topic_id, keyword FROM dwh.dim_topic", con=engine_dwh)
        
        # Get time_id from dim_time
        time_map = pd.read_sql("""
            SELECT time_id, timestamp::date as date 
            FROM dwh.dim_time
        """, con=engine_dwh)
        
        # Filter only tweets that exist in dim_tweet
        df = df[df['tweet_id'].isin(tweet_map['tweet_id'])]
        
        # Merge with topic and time dimensions
        df = df.merge(topic_map, left_on='matched_product', right_on='keyword', how='left')
        df['date'] = pd.to_datetime(df['timestamp']).dt.date
        df = df.merge(time_map, on='date', how='left')
        
        # Select and rename columns to match the fact table
        fact_data = df[['tweet_id', 'topic_id', 'time_id', 'polarity']].dropna()
        
        if not fact_data.empty:
            # Insert only new records
            existing_records = pd.read_sql(
                "SELECT tweet_id, topic_id, time_id FROM dwh.fact_sentiment", 
                con=engine_dwh
            )
            
            if not existing_records.empty:
                # Create a composite key for comparison
                existing_records['composite_key'] = existing_records.astype(str).apply('_'.join, axis=1)
                fact_data['composite_key'] = fact_data.astype(str).apply('_'.join, axis=1)
                fact_data = fact_data[~fact_data['composite_key'].isin(existing_records['composite_key'])]
                fact_data = fact_data.drop('composite_key', axis=1)
            
            if not fact_data.empty:
                # Insert new records
                fact_data.to_sql(
                    'fact_sentiment', 
                    con=engine_dwh, 
                    schema='dwh', 
                    if_exists='append', 
                    index=False
                )
                print(f"Berhasil menambahkan {len(fact_data)} data sentimen baru")
            else:
                print("Tidak ada data sentimen baru yang perlu ditambahkan")
        else:
            print("Tidak ada data yang memenuhi syarat untuk dimasukkan ke fact_sentiment")
            
    except Exception as e:
        print(f"Error saat memuat data ke fact_sentiment: {str(e)}")
        raise

def load_fact_temperature():
    """Memuat data suhu ke dalam fact table"""
    try:
        print("\nMemulai proses load data ke fact_temperature...")
        
        # Hanya ambil data yang belum ada di fact_temperature
        query = """
        SELECT s.sensor_id, s.temperature, s.timestamp
        FROM staging_warehouse_temp_sensor s
        LEFT JOIN dwh.fact_temperature ft ON s.sensor_id = ft.sensor_id 
            AND s.timestamp = ft.timestamp
        WHERE ft.sensor_id IS NULL
        """
        df = pd.read_sql(query, con=engine_stag)
        
        if df.empty:
            print("Tidak ada data suhu baru yang ditemukan.")
            return
            
        # Dapatkan time_id untuk setiap timestamp
        df['date'] = pd.to_datetime(df['timestamp']).dt.date
        time_map = pd.read_sql("SELECT time_id, date FROM dwh.dim_time", con=engine_dwh)
        df = df.merge(time_map, on='date', how='left')
        
        # Siapkan data untuk dimasukkan
        fact_data = df[['sensor_id', 'temperature', 'timestamp', 'time_id']]
        
        fact_data.to_sql('fact_temperature', con=engine_dwh, schema='dwh', 
                        if_exists='append', index=False)
        
        print(f"Berhasil memuat {len(fact_data)} data suhu baru ke fact_temperature")
        
    except Exception as e:
        print(f"Error saat memuat data ke fact_temperature: {str(e)}")

def create_and_populate_dim_time():
    """Membuat dan mengisi tabel dim_time dengan data tanggal"""
    try:
        print("\nMemulai pembuatan dan pengisian tabel dim_time...")
        
        create_table_sql = text("""
        CREATE TABLE IF NOT EXISTS dwh.dim_time (
            time_id INT NOT NULL UNIQUE,
            timestamp TIMESTAMP NOT NULL,
            year INT NOT NULL,
            month INT NOT NULL,
            day INT NOT NULL,
            hour INT NOT NULL
        )
        """)
        
        # Use a connection to execute the SQL
        with engine_dwh.connect() as connection:
            connection.execute(create_table_sql)
            connection.commit()
        print("Tabel dim_time berhasil dibuat/ditemukan.")
        
        # Tentukan rentang tanggal yang ingin diisi (contoh: 5 tahun terakhir)
        end_date = datetime.now().date()
        start_date = end_date - pd.DateOffset(years=5)
        date_range = pd.date_range(start=start_date, end=end_date, freq='D')
        
        # Buat DataFrame untuk dim_time dengan format yang diminta
        dim_time = pd.DataFrame({
            'timestamp': date_range,
            'year': date_range.year,
            'month': date_range.month,
            'day': date_range.day,
            'hour': 0  # Default hour to 0 since we're only dealing with daily data
        })
        
        # Generate time_id as integer in format YYYYMMDD
        dim_time['time_id'] = (dim_time['year'].astype(str) + 
                             dim_time['month'].astype(str).str.zfill(2) + 
                             dim_time['day'].astype(str).str.zfill(2)).astype(int)
        
        # Reorder columns to put time_id first
        dim_time = dim_time[['time_id', 'timestamp', 'year', 'month', 'day', 'hour']]
        
        # Hanya masukkan tanggal yang belum ada
        existing_dates = pd.read_sql("SELECT time_id FROM dwh.dim_time", con=engine_dwh)
        if not existing_dates.empty:
            dim_time = dim_time[~dim_time['time_id'].isin(existing_dates['time_id'])]
        
        if not dim_time.empty:
            dim_time.to_sql('dim_time', con=engine_dwh, schema='dwh', 
                          if_exists='append', index=False)
            print(f"Berhasil menambahkan {len(dim_time)} tanggal baru ke dim_time")
        else:
            print("Tidak ada tanggal baru yang perlu ditambahkan ke dim_time")
            
    except Exception as e:
        print(f"Error saat mengisi dim_time: {str(e)}")
        raise

def load_dim_sensor():
    """Memuat data sensor ke dalam dimensi"""
    try:
        print("\nMemulai proses load data ke dim_sensor...")
        
        # Create dim_sensor table if it doesn't exist
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS dwh.dim_sensor (
            sensor_id VARCHAR(50) PRIMARY KEY,
            temperature_c FLOAT
        )
        """
        with engine_dwh.connect() as connection:
            connection.execute(text(create_table_sql))
            connection.commit()
        print("Tabel dim_sensor siap digunakan.")
        
        # Get all sensors and temperature from staging_warehouse_temp_sensor
        query = """
        SELECT sensor_id, temperature_c
        FROM staging_warehouse_temp_sensor
        """
        
        # Read sensor data from staging
        df = pd.read_sql(query, con=engine_stag)
        
        if not df.empty:
            # Insert all sensors into dim_sensor
            # Using to_sql with method='multi' for better performance
            df.to_sql('dim_sensor', 
                     con=engine_dwh, 
                     schema='dwh',
                     if_exists='append', 
                     index=False,
                     method='multi')
            print(f"Berhasil menambahkan {len(df)} data sensor ke dim_sensor")
        else:
            print("Tidak ada data sensor yang ditemukan di staging")
            
    except Exception as e:
        print(f"Error saat memuat data ke dim_sensor: {str(e)}")
        raise

def create_fact_temperature_table(engine_dwh):
    """Creates the fact_temperature table if it doesn't exist."""
    from sqlalchemy import text
    
    create_table_sql = text("""
    CREATE TABLE IF NOT EXISTS dwh.fact_temperature (
        fact_id SERIAL PRIMARY KEY,
        sensor_id VARCHAR REFERENCES dwh.dim_sensor(sensor_id),
        time_id INT REFERENCES dwh.dim_time(time_id),
        temperature_c FLOAT,
        UNIQUE (sensor_id, time_id)  -- Prevents duplicate entries for same sensor and time
    )
    """)
    
    create_index_sql = text("""
    CREATE INDEX IF NOT EXISTS idx_fact_temp_sensor_time ON dwh.fact_temperature(sensor_id, time_id);
    """)
    
    with engine_dwh.connect() as conn:
        conn.execute(create_table_sql)
        conn.execute(create_index_sql)
        conn.commit()
    print("Tabel fact_temperature berhasil dibuat/diperbarui.")

def populate_fact_temperature(engine_dwh, process_date=None):
    """
    Populates fact_temperature by joining dim_sensor and dim_time.
    
    Parameters:
    - engine_dwh: SQLAlchemy engine
    - process_date: Date in 'YYYY-MM-DD' format. If None, uses current date.
    """
    from sqlalchemy import text
    from datetime import datetime, timedelta
    
    try:
        # Set the processing date
        if process_date is None:
            process_date = datetime.now().date()
        else:
            process_date = datetime.strptime(process_date, '%Y-%m-%d').date()
        
        print(f"\nMemproses data suhu untuk tanggal: {process_date}")
        
        # Insert query that joins dim_sensor and dim_time to get correct time_id for each reading
        insert_query = text("""
        INSERT INTO dwh.fact_temperature (sensor_id, time_id, temperature_c)
        SELECT 
            ds.sensor_id,
            dt.time_id,
            ds.temperature_c
        FROM dwh.dim_sensor ds
        JOIN dwh.dim_time dt ON 
            EXTRACT(YEAR FROM dt.timestamp) = dt.year AND
            EXTRACT(MONTH FROM dt.timestamp) = dt.month AND
            EXTRACT(DAY FROM dt.timestamp) = dt.day AND
            EXTRACT(HOUR FROM dt.timestamp) = dt.hour
        WHERE ds.temperature_c IS NOT NULL
        AND DATE(dt.timestamp) = :target_date
        AND NOT EXISTS (
            SELECT 1 
            FROM dwh.fact_temperature ft 
            WHERE ft.sensor_id = ds.sensor_id 
            AND ft.time_id = dt.time_id
        )
        """)
        
        with engine_dwh.connect() as conn:
            # Execute the insert query
            result = conn.execute(
                insert_query,
                {'target_date': process_date}
            )
            conn.commit()
            
            if result.rowcount > 0:
                print(f"✅ Berhasil menambahkan {result.rowcount} data suhu baru")
            else:
                print("ℹ️ Tidak ada data suhu baru yang perlu ditambahkan")
                
            # Verifikasi data yang sudah ada
            check_query = text("""
            SELECT COUNT(*) 
            FROM dwh.fact_temperature ft
            JOIN dwh.dim_time dt ON ft.time_id = dt.time_id
            WHERE dt.year = :year AND dt.month = :month AND dt.day = :day
            """)
            
            count_result = conn.execute(
                check_query,
                {'year': process_date.year, 'month': process_date.month, 'day': process_date.day}
            ).scalar()
            
            print(f"📊 Total data suhu untuk tanggal {process_date}: {count_result} record")
            
            # Tampilkan ringkasan data yang baru ditambahkan
            if result.rowcount > 0:
                summary_query = text("""
                SELECT 
                    MIN(ft.temperature_c) as min_temp,
                    MAX(ft.temperature_c) as max_temp,
                    AVG(ft.temperature_c) as avg_temp,
                    COUNT(DISTINCT dt.time_id) as unique_timestamps
                FROM dwh.fact_temperature ft
                JOIN dwh.dim_time dt ON ft.time_id = dt.time_id
                WHERE dt.year = :year AND dt.month = :month AND dt.day = :day
                """)
                
                summary = conn.execute(
                    summary_query,
                    {'year': process_date.year, 'month': process_date.month, 'day': process_date.day}
                ).fetchone()
                
                print(f"🌡️  Statistik Suhu:")
                print(f"   - Rata-rata: {summary.avg_temp:.2f}°C")
                print(f"   - Minimum: {summary.min_temp:.2f}°C")
                print(f"   - Maksimum: {summary.max_temp:.2f}°C")
                print(f"   - Jumlah timestamp unik: {summary.unique_timestamps}")
                
    except Exception as e:
        print(f"Error saat memproses data suhu: {str(e)}")
        raise

# Example usage:
# 1. First, create the table (run once)
# create_fact_temperature_table(engine_dwh)

# 2. Then populate data (can be run daily)
# populate_fact_temperature(engine_dwh)  # For current date
# populate_fact_temperature(engine_dwh, '2023-06-23')  # For specific date

def run_etl():
    """Menjalankan seluruh proses ETL"""
    print("Memulai proses ETL...")
    
    # Periksa data di staging
    check_staging_data()
    
    # Buat dan isi dim_time jika belum ada
    create_and_populate_dim_time()
    
    # Load data ke dimensi
    load_dim_competitor()
    load_dim_tweet()
    load_dim_topic()
    load_dim_sensor()
    
    # Load data ke fact tables
    load_fact_competitor_share()
    load_fact_sentiment()
    load_fact_temperature()
    populate_fact_temperature(engine_dwh)
    
    print("\nProses ETL selesai!")

if __name__ == "__main__":
    run_etl()

# Update the visualization code in structure.py

# Create a new figure for the dashboard
fig_dashboard = Figure(figsize=(12, 12))
gs = fig_dashboard.add_gridspec(2, 1, height_ratios=[1, 1])

# Temperature Plot
ax_temp = fig_dashboard.add_subplot(gs[0])
try:
    # Query temperature data from fact_temperature joined with dim_time
    query = """
    SELECT 
        ft.temperature_c,
        dt.year,
        dt.month,
        dt.day,
        dt.hour
    FROM dwh.fact_temperature ft
    JOIN dwh.dim_time dt ON ft.time_id = dt.time_id
    ORDER BY dt.year, dt.month, dt.day, dt.hour
    """
    df_temp = pd.read_sql(query, con=engine_dwh)
    
    if not df_temp.empty:
        # Create a datetime column for plotting
        df_temp['datetime'] = pd.to_datetime(
            df_temp[['year', 'month', 'day', 'hour']].astype(str).agg('-'.join, axis=1),
            format='%Y-%m-%d-%H'
        )
        
        # Plot temperature over time
        ax_temp.plot(df_temp['datetime'], df_temp['temperature_c'], 
                    marker='o', linestyle='-', color='tab:red')
        
        # Customize the plot
        ax_temp.set_title('Temperature Trends Over Time', fontsize=14, pad=20)
        ax_temp.set_xlabel('Date and Time', fontsize=12)
        ax_temp.set_ylabel('Temperature (°C)', fontsize=12)
        ax_temp.grid(True, linestyle='--', alpha=0.7)
        
        # Rotate x-axis labels for better readability
        plt.setp(ax_temp.get_xticklabels(), rotation=45, ha='right')
        fig_dashboard.tight_layout()
        
    else:
        ax_temp.text(0.5, 0.5, 'No temperature data available', 
                    horizontalalignment='center', 
                    verticalalignment='center',
                    transform=ax_temp.transAxes)
        ax_temp.set_xticks([])
        ax_temp.set_yticks([])
        
except Exception as e:
    print(f"Error generating temperature plot: {e}")
    ax_temp.text(0.5, 0.5, 'Error loading temperature data', 
                horizontalalignment='center', 
                verticalalignment='center',
                transform=ax_temp.transAxes)
    ax_temp.set_xticks([])
    ax_temp.set_yticks([])

# Word Cloud
ax_wc = fig_dashboard.add_subplot(gs[1])
try:
    # Fetch tweet data
    tweet_query = """
    SELECT dt.tweet_text 
    FROM dwh.dim_tweet dt
    JOIN dwh.fact_sentiment fs ON dt.tweet_id = fs.tweet_id
    """
    
    df_tweets = pd.read_sql(tweet_query, con=engine_dwh)
    
    if not df_tweets.empty and 'tweet_text' in df_tweets.columns:
        # Combine all tweets into a single string
        text = ' '.join(tweet for tweet in df_tweets['tweet_text'].dropna())
        
        if text.strip():  # Only generate word cloud if there's text
            # Generate word cloud
            wordcloud = WordCloud(
                width=800, 
                height=400, 
                background_color='white',
                max_words=200,
                contour_width=3,
                contour_color='steelblue'
            ).generate(text)
            
            # Display the word cloud
            ax_wc.imshow(wordcloud, interpolation='bilinear')
            ax_wc.axis('off')
            ax_wc.set_title('Word Cloud of Tweets', fontsize=14, pad=20)
        else:
            ax_wc.text(0.5, 0.5, 'No tweet text available', 
                     horizontalalignment='center', 
                     verticalalignment='center',
                     transform=ax_wc.transAxes)
            ax_wc.set_xticks([])
            ax_wc.set_yticks([])
    else:
        ax_wc.text(0.5, 0.5, 'No tweet data available', 
                 horizontalalignment='center', 
                 verticalalignment='center',
                 transform=ax_wc.transAxes)
        ax_wc.set_xticks([])
        ax_wc.set_yticks([])
        
except Exception as e:
    print(f"Error generating word cloud: {e}")
    ax_wc.text(0.5, 0.5, 'Error loading tweet data', 
              horizontalalignment='center', 
              verticalalignment='center',
              transform=ax_wc.transAxes)
    ax_wc.set_xticks([])
    ax_wc.set_yticks([])

# Create the main application window
root = tk.Tk()
root.title("Data Warehouse Visualization Dashboard")
root.geometry("1200x1000")

# Create a frame for the dashboard
frame = tk.Frame(root)
frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)

# Add a title
title_label = tk.Label(
    frame, 
    text="Data Warehouse Analytics Dashboard", 
    font=("Arial", 18, "bold")
)
title_label.pack(pady=(0, 20))

# Create canvas for the dashboard
canvas = FigureCanvasTkAgg(fig_dashboard, master=frame)
canvas.draw()
canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

# Add a status bar
status_bar = tk.Label(
    root, 
    text="Dashboard loaded successfully | Data last updated: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    bd=1, 
    relief=tk.SUNKEN, 
    anchor=tk.W
)
status_bar.pack(side=tk.BOTTOM, fill=tk.X)

# Add some padding around the window
root.update()
canvas_width = canvas.get_width_height()[0]
root.minsize(canvas_width + 40, 800)

# Run the application
root.mainloop()
